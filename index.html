<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance</title>
<style>
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }

    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.6;
        color: #333;
        background-color: #f8f9fa;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
    }

    header {
        text-align: center;
        margin-bottom: 40px;
        background: white;
        padding: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    h1 {
        font-size: 2.5em;
        color: #2c3e50;
        margin-bottom: 20px;
    }

    .authors {
        font-size: 1.1em;
        color: #666;
        margin-bottom: 20px;
    }

    .abstract {
        background: white;
        padding: 30px;
        margin-bottom: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .abstract h2 {
        color: #2c3e50;
        margin-bottom: 15px;
    }

    .demo-section {
        background: white;
        padding: 30px;
        margin-bottom: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .table-container {
        overflow-x: auto;
        margin-top: 20px;
        border: 1px solid #ddd;
        border-radius: 5px;
    }

    .demo-table {
        width: 100%;
        min-width: 1000px;
        border-collapse: collapse;
    }

    .demo-table th,
    .demo-table td {
        border: 1px solid #ddd;
        padding: 15px;
        text-align: center;
        vertical-align: middle;
    }

    .demo-table th {
        background-color: #f8f9fa;
        font-weight: bold;
        color: #2c3e50;
        position: sticky;
        top: 0;
        z-index: 10;
    }

    .waveform-container {
        position: relative;
        width: 200px;
        height: 80px;
        margin: 10px auto;
        background: #f0f0f0;
        border-radius: 5px;
        overflow: hidden;
    }

    .waveform-canvas {
        width: 100%;
        height: 100%;
        display: block;
    }

    .waveform-loading {
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        font-size: 12px;
        color: #666;
    }

    .progress-line {
        position: absolute;
        top: 0;
        left: 0;
        width: 2px;
        height: 100%;
        background: #3498db;
        opacity: 0;
        transition: left 0.1s ease;
        z-index: 5;
    }

    .audio-controls {
        display: flex;
        justify-content: center;
        align-items: center;
        gap: 10px;
        margin-top: 10px;
    }

    .play-btn {
        background: #2c3e50;
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: 5px;
        cursor: pointer;
        font-size: 14px;
        transition: background 0.3s;
    }

    .play-btn:hover {
        background: #34495e;
    }

    .play-btn.playing {
        background: #e74c3c;
    }

    .play-btn:disabled {
        background: #bdc3c7;
        cursor: not-allowed;
    }

    .transcript-section {
        background: white;
        padding: 30px;
        margin-bottom: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .transcript-box {
        background: #f8f9fa;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 20px;
        margin-top: 15px;
        font-family: 'Courier New', monospace;
        line-height: 1.8;
    }

    .transcript-selector {
        margin-bottom: 15px;
    }

    .transcript-selector select {
        padding: 8px 12px;
        border: 1px solid #ddd;
        border-radius: 5px;
        font-size: 14px;
    }

    .id-column {
        background-color: #f8f9fa;
        font-weight: bold;
        width: 50px;
        position: sticky;
        left: 0;
        z-index: 5;
    }

    .note {
        background: #e8f4fd;
        border-left: 4px solid #3498db;
        padding: 15px;
        margin: 20px 0;
        border-radius: 0 5px 5px 0;
    }

    .audio-duration {
        font-size: 12px;
        color: #666;
        margin-top: 5px;
    }

    .error-message {
        color: #e74c3c;
        font-size: 12px;
        margin-top: 5px;
    }

    /* Scrollbar styling */
    .table-container::-webkit-scrollbar {
        height: 8px;
    }

    .table-container::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }

    .table-container::-webkit-scrollbar-thumb {
        background: #888;
        border-radius: 4px;
    }

    .table-container::-webkit-scrollbar-thumb:hover {
        background: #555;
    }

    .waveform-canvas {
        width: 100%;
        height: 100%;
        display: block;
        cursor: pointer; /* Add this line */
    }

    .waveform-canvas:hover {
        opacity: 0.8;
    }
</style>
</head>
<body>
<div class="container">
    <header>
        <h1>Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance</h1>
        <div class="authors">
            Wenqian Cui¹, Xiaohui Li², Lei Zhu², Zhihan Guo¹, Haoli Bai², Lu Hou², Irwin King¹<br>
            ¹The Chinese University of Hong Kong, ²Huawei Noah's Ark Lab
        </div>
        <div style="margin-top: 20px;">
            <a href="#" style="margin: 0 10px; color: #3498db; text-decoration: none;">[Paper (Coming Soon)]</a>
            <a href="#" style="margin: 0 10px; color: #3498db; text-decoration: none;">[Code (Coming Soon)]</a>
            <a href="#" style="margin: 0 10px; color: #3498db; text-decoration: none;">[Demo]</a>
        </div>
    </header>

    <section class="abstract">
        <h2>Abstract</h2>
        <p>Full-Duplex Speech Language Models (FD-SLMs) are specialized speech foundation models designed to enable natural, real-time spoken interactions by capturing complex conversational dynamics, such as interruptions, backchannels, and overlapping speech. While cascaded FD-SLMs rely on external modules to learn discrete, predefined behaviors for duplex communications, end-to-end (e2e) FD-SLMs leverage real-world conversational data, enabling models to capture nuanced dialogue patterns for more human-like interactions---a key advantage that motivates our focus on e2e systems. However, e2e FD-SLMs face a significant challenge: their conversational abilities often degrade compared to text-based Large Language Models due to the prolonged nature of speech sequences and the scarcity of high-quality spoken dialogue data. To address this, we propose a novel planning-inspired methodology, <b>TurnGuide</b>, for integrating turn-level text guidance into double-channel spoken conversational contexts. Our approach dynamically segments the assistant's speech into dialogue turns and trains the assistant to first output text guidance for each turn before generating the corresponding speech. This not only aligns with conversational flow but also addresses the critical issues of timing and length of text guidance. Extensive experiments demonstrate that our method significantly enhances e2e FD-SLMs' ability to generate semantically meaningful and coherent speech, while preserving the natural flow of full-duplex spoken dialogues.</p>
    </section>

    <section class="demo-section">
        <h2>Audio Demonstrations</h2>
        <div class="note">
            <strong>Note:</strong> The first 30 seconds of audio serves as the prompt to the model, and the model generates a 90 seconds continuations.
        </div>

        <div class="table-container">
            <table class="demo-table">
                <thead>
                    <tr>
                        <th rowspan="2" class="id-column">ID</th>
                        <th>Original Speech</th>
                        <th colspan="4">Synthesized Speech Continuation</th>
                    </tr>
                    <tr>
                        <th>Prompt</th>
                        <th>Ground Truth</th>
                        <th>TurnGuide (Our Method)</th>
                        <th>Baseline FD-SLM</th>
                        <th>Cascaded Method</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="id-column">0</td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-prompt" onclick="seekAudio('0-prompt', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-prompt">Loading...</div>
                                <div class="progress-line" id="progress-0-prompt"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-prompt')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-prompt"></div>
                            <div class="error-message" id="error-0-prompt"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-ground" onclick="seekAudio('0-ground', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-ground">Loading...</div>
                                <div class="progress-line" id="progress-0-ground"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-ground')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-ground"></div>
                            <div class="error-message" id="error-0-ground"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-turnguide" onclick="seekAudio('0-turnguide', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-turnguide">Loading...</div>
                                <div class="progress-line" id="progress-0-turnguide"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-turnguide')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-turnguide"></div>
                            <div class="error-message" id="error-0-turnguide"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-baseline" onclick="seekAudio('0-baseline', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-baseline">Loading...</div>
                                <div class="progress-line" id="progress-0-baseline"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-baseline')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-baseline"></div>
                            <div class="error-message" id="error-0-baseline"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-cascaded" onclick="seekAudio('0-cascaded', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-cascaded">Loading...</div>
                                <div class="progress-line" id="progress-0-cascaded"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-cascaded')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-cascaded"></div>
                            <div class="error-message" id="error-0-cascaded"></div>
                        </td>
                    </tr>
                    <tr>
                        <td class="id-column">1</td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-prompt" onclick="seekAudio('1-prompt', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-prompt">Loading...</div>
                                <div class="progress-line" id="progress-1-prompt"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-prompt')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-prompt"></div>
                            <div class="error-message" id="error-1-prompt"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-ground" onclick="seekAudio('1-ground', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-ground">Loading...</div>
                                <div class="progress-line" id="progress-1-ground"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-ground')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-ground"></div>
                            <div class="error-message" id="error-1-ground"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-turnguide" onclick="seekAudio('1-turnguide', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-turnguide">Loading...</div>
                                <div class="progress-line" id="progress-1-turnguide"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-turnguide')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-turnguide"></div>
                            <div class="error-message" id="error-1-turnguide"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-baseline" onclick="seekAudio('1-baseline', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-baseline">Loading...</div>
                                <div class="progress-line" id="progress-1-baseline"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-baseline')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-baseline"></div>
                            <div class="error-message" id="error-1-baseline"></div>
                        </td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-cascaded" onclick="seekAudio('1-cascaded', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-cascaded">Loading...</div>
                                <div class="progress-line" id="progress-1-cascaded"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-cascaded')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-cascaded"></div>
                            <div class="error-message" id="error-1-cascaded"></div>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </section>

    <section class="transcript-section">
        <h2>Audio Transcripts</h2>
        <div class="transcript-selector">
            <label for="transcript-select">Select Audio Sample: </label>
            <select id="transcript-select" onchange="showTranscript()">
                <option value="0-prompt">Sample 0 - Prompt</option>
                <option value="0-ground">Sample 0 - Ground Truth</option>
                <option value="0-turnguide">Sample 0 - TurnGuide (Our Method)</option>
                <option value="0-baseline">Sample 0 - Baseline FD-SLM</option>
                <option value="0-cascaded">Sample 0 - Cascaded</option>
                <option value="1-prompt">Sample 1 - Prompt</option>
                <option value="1-ground">Sample 1 - Ground Truth</option>
                <option value="1-turnguide">Sample 1 - TurnGuide (Our Method)</option>
                <option value="1-baseline">Sample 1 - Baseline FD-SLM</option>
                <option value="1-cascaded">Sample 1 - Cascaded</option>
            </select>
        </div>
        <div class="transcript-box" id="transcript-display">
            Select an audio sample to view its transcript.
        </div>
    </section>
</div>

<script>
    // Sample transcripts (replace with your actual transcripts)
    const transcripts = {
        '0-prompt': 'This is the beginning of the first speech sample...',
        '0-ground': 'This is the ground truth continuation of the first sample...',
        '0-turnguide': 'This is the TurnGuide continuation of the first sample...',
        '0-baseline': 'This is the baseline FD-SLM continuation of the first sample...',
        '0-cascaded': 'This is the cascaded model continuation of the first sample...',
        '1-prompt': 'This is the beginning of the second speech sample...',
        '1-ground': 'This is the ground truth continuation of the second sample...',
        '1-turnguide': 'This is the TurnGuide continuation of the second sample...',
        '1-baseline': 'This is the baseline FD-SLM continuation of the second sample...',
        '1-cascaded': 'This is the cascaded model continuation of the second sample...'
    };

    let currentlyPlaying = null;
    let audioElements = {};
    let waveformData = {};
    let audioContext = null;

    function formatTime(seconds) {
        const mins = Math.floor(seconds / 60);
        const secs = Math.floor(seconds % 60);
        return `${mins}:${secs.toString().padStart(2, '0')}`;
    }

    async function loadWaveform(audioId) {
        const canvas = document.getElementById(`waveform-${audioId}`);
        const loadingElement = document.getElementById(`loading-${audioId}`);
        const errorElement = document.getElementById(`error-${audioId}`);
        
        if (!canvas) return;
        
        try {
            // Initialize audio context if not already done
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            // Fetch audio file
            const response = await fetch(`audio/${audioId}.mp3`);
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Extract audio data (use first channel)
            const channelData = audioBuffer.getChannelData(0);
            const samples = channelData.length;
            const canvasWidth = canvas.width = 200;
            const canvasHeight = canvas.height = 80;
            
            // Calculate how many samples per pixel
            const samplesPerPixel = Math.floor(samples / canvasWidth);
            const waveformPoints = [];
            
            // Create waveform data by finding peak values for each pixel
            for (let i = 0; i < canvasWidth; i++) {
                const start = i * samplesPerPixel;
                const end = start + samplesPerPixel;
                let max = 0;
                
                for (let j = start; j < end && j < samples; j++) {
                    const sample = Math.abs(channelData[j]);
                    if (sample > max) {
                        max = sample;
                    }
                }
                
                waveformPoints.push(max);
            }
            
            // Store waveform data for progress animation
            waveformData[audioId] = waveformPoints;
            
            // Draw initial waveform
            drawWaveform(canvas, waveformPoints, 0);

            // Hide loading indicator
            loadingElement.style.display = 'none';

            // Make canvas clickable by adding event listener (backup method)
            canvas.style.cursor = 'pointer';
            
        } catch (error) {
            console.error(`Error loading waveform for ${audioId}:`, error);
            errorElement.textContent = 'Error loading waveform';
            loadingElement.style.display = 'none';
        }
    }

    function drawWaveform(canvas, waveformPoints, progress = 0) {
        const ctx = canvas.getContext('2d');
        const width = canvas.width;
        const height = canvas.height;
        
        // Clear canvas
        ctx.clearRect(0, 0, width, height);
        
        // Draw waveform
        const barWidth = width / waveformPoints.length;
        const progressIndex = Math.floor(progress * waveformPoints.length);
        
        for (let i = 0; i < waveformPoints.length; i++) {
            const barHeight = waveformPoints[i] * height * 0.8; // Scale to 80% of canvas height
            const x = i * barWidth;
            const y = (height - barHeight) / 2;
            
            // Color based on progress
            if (i <= progressIndex) {
                ctx.fillStyle = '#3498db'; // Blue for played portion
            } else {
                ctx.fillStyle = '#e74c3c'; // Red for unplayed portion
            }
            
            ctx.fillRect(x, y, Math.max(barWidth - 1, 1), barHeight);
        }
    }

    function updateWaveformProgress(audioId, progress) {
        const canvas = document.getElementById(`waveform-${audioId}`);
        if (canvas && waveformData[audioId]) {
            drawWaveform(canvas, waveformData[audioId], progress);
        }
    }

    function playAudio(audioId) {
        const button = event.target;
        const progressLine = document.getElementById(`progress-${audioId}`);
        const durationElement = document.getElementById(`duration-${audioId}`);
        const errorElement = document.getElementById(`error-${audioId}`);
        
        // Clear any previous error messages
        errorElement.textContent = '';
        
        // Stop any currently playing audio
        if (currentlyPlaying && currentlyPlaying !== audioId) {
            stopAudio(currentlyPlaying);
        }
        
        if (currentlyPlaying === audioId) {
            // Pause current audio
            stopAudio(audioId);
            return;
        }
        
        // Create audio element if it doesn't exist
        if (!audioElements[audioId]) {
            audioElements[audioId] = new Audio(`audio/${audioId}.mp3`);
            
            // Add event listeners
            audioElements[audioId].addEventListener('loadedmetadata', () => {
                const duration = audioElements[audioId].duration;
                durationElement.textContent = `Duration: ${formatTime(duration)}`;
            });
            
            audioElements[audioId].addEventListener('timeupdate', () => {
                const audio = audioElements[audioId];
                const progress = audio.currentTime / audio.duration;
                const progressPx = progress * 200; // 200px is the width
                progressLine.style.left = progressPx + 'px';
                
                // Update waveform progress
                updateWaveformProgress(audioId, progress);
            });
            
            audioElements[audioId].addEventListener('ended', () => {
                stopAudio(audioId);
            });
            
            audioElements[audioId].addEventListener('error', (e) => {
                console.error(`Error loading audio ${audioId}:`, e);
                errorElement.textContent = 'Error loading audio file';
                button.disabled = false;
                button.textContent = '▶ Play';
                button.classList.remove('playing');
            });
            
            audioElements[audioId].addEventListener('canplay', () => {
                button.disabled = false;
            });
        }
        
        // Start playing
        currentlyPlaying = audioId;
        button.textContent = '⏸ Pause';
        button.classList.add('playing');
        button.disabled = true; // Disable during loading
        progressLine.style.opacity = '1';
        
        // Play the audio
        audioElements[audioId].play().then(() => {
            button.disabled = false;
        }).catch((error) => {
            console.error(`Error playing audio ${audioId}:`, error);
            errorElement.textContent = 'Error playing audio file';
            stopAudio(audioId);
        });
    }

    function stopAudio(audioId) {
        const button = document.querySelector(`button[onclick="playAudio('${audioId}')"]`);
        const progressLine = document.getElementById(`progress-${audioId}`);
        
        if (audioElements[audioId]) {
            audioElements[audioId].pause();
            audioElements[audioId].currentTime = 0;
        }
        
        button.textContent = '▶ Play';
        button.classList.remove('playing');
        button.disabled = false;
        progressLine.style.opacity = '0';
        progressLine.style.left = '0px';
        
        // Reset waveform progress
        updateWaveformProgress(audioId, 0);
        
        if (currentlyPlaying === audioId) {
            currentlyPlaying = null;
        }
    }

    function showTranscript() {
        const select = document.getElementById('transcript-select');
        const display = document.getElementById('transcript-display');
        const selectedValue = select.value;
        
        if (transcripts[selectedValue]) {
            display.textContent = transcripts[selectedValue];
        } else {
            display.textContent = 'Transcript not available for this sample.';
        }
    }

    // Initialize waveforms and transcript display
    document.addEventListener('DOMContentLoaded', async () => {
        // Load waveforms for all audio samples
        const audioIds = [
            '0-prompt', '0-ground', '0-turnguide', '0-baseline', '0-cascaded',
            '1-prompt', '1-ground', '1-turnguide', '1-baseline', '1-cascaded'
        ];
        
        // Load waveforms asynchronously
        for (const id of audioIds) {
            loadWaveform(id);
        }
        
        showTranscript();
    });

    // Stop all audio when page is unloaded
    window.addEventListener('beforeunload', () => {
        Object.values(audioElements).forEach(audio => {
            audio.pause();
        });
        if (audioContext) {
            audioContext.close();
        }
    });
</script>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance</title>
<style>
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }

    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.6;
        color: #333;
        background-color: #f8f9fa;
    }

    .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
    }

    header {
        text-align: center;
        margin-bottom: 40px;
        background: white;
        padding: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    h1 {
        font-size: 2.5em;
        color: #2c3e50;
        margin-bottom: 20px;
    }

    .authors {
        font-size: 1.1em;
        color: #666;
        margin-bottom: 20px;
    }

    .abstract {
        background: white;
        padding: 30px;
        margin-bottom: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .abstract h2 {
        color: #2c3e50;
        margin-bottom: 15px;
    }

    .demo-section {
        background: white;
        padding: 30px;
        margin-bottom: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .table-container {
        overflow-x: auto;
        margin-top: 20px;
        border: 1px solid #ddd;
        border-radius: 5px;
    }

    .demo-table {
        width: 100%;
        min-width: 1200px;
        border-collapse: collapse;
    }

    .demo-table th,
    .demo-table td {
        border: 1px solid #ddd;
        padding: 15px;
        text-align: center;
        vertical-align: middle;
    }

    .demo-table th {
        background-color: #f8f9fa;
        font-weight: bold;
        color: #2c3e50;
        position: sticky;
        top: 0;
        z-index: 10;
    }

    .waveform-container {
        position: relative;
        width: 200px;
        height: 80px;
        margin: 10px auto;
        background: #f0f0f0;
        border-radius: 5px;
        overflow: hidden;
    }

    .waveform-canvas {
        width: 100%;
        height: 100%;
        display: block;
    }

    .waveform-loading {
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        font-size: 12px;
        color: #666;
    }

    .progress-line {
        position: absolute;
        top: 0;
        left: 0;
        width: 2px;
        height: 100%;
        background: #3498db;
        opacity: 0;
        transition: left 0.1s ease;
        z-index: 5;
    }

    .audio-controls {
        display: flex;
        justify-content: center;
        align-items: center;
        gap: 10px;
        margin-top: 10px;
    }

    .play-btn {
        background: #2c3e50;
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: 5px;
        cursor: pointer;
        font-size: 14px;
        transition: background 0.3s;
    }

    .play-btn:hover {
        background: #34495e;
    }

    .play-btn.playing {
        background: #e74c3c;
    }

    .play-btn:disabled {
        background: #bdc3c7;
        cursor: not-allowed;
    }

    .transcript-section {
        background: white;
        padding: 30px;
        margin-bottom: 40px;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }

    .transcript-box {
        background: #f8f9fa;
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 20px;
        margin-top: 15px;
        font-family: 'Courier New', monospace;
        line-height: 1.8;
        white-space: pre-wrap; /* Add this line to preserve line breaks */
        word-wrap: break-word; /* Add this line for better word wrapping */
        max-height: 300px; /* Add this line to limit height */
        overflow-y: auto; /* Add this line for scrolling if content is too long */
    }

    .transcript-selector {
        margin-bottom: 15px;
    }

    .transcript-selector select {
        padding: 8px 12px;
        border: 1px solid #ddd;
        border-radius: 5px;
        font-size: 14px;
    }

    .id-column {
        background-color: #f8f9fa;
        font-weight: bold;
        width: 50px;
        position: sticky;
        left: 0;
        z-index: 5;
    }

    .note {
        background: #e8f4fd;
        border-left: 4px solid #3498db;
        padding: 15px;
        margin: 20px 0;
        border-radius: 0 5px 5px 0;
    }

    .audio-duration {
        font-size: 12px;
        color: #666;
        margin-top: 5px;
    }

    .error-message {
        color: #e74c3c;
        font-size: 12px;
        margin-top: 5px;
    }

    /* Scrollbar styling */
    .table-container::-webkit-scrollbar {
        height: 8px;
    }

    .table-container::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }

    .table-container::-webkit-scrollbar-thumb {
        background: #888;
        border-radius: 4px;
    }

    .table-container::-webkit-scrollbar-thumb:hover {
        background: #555;
    }

    .waveform-canvas {
        width: 100%;
        height: 100%;
        display: block;
        cursor: pointer; /* Add this line */
    }

    .waveform-canvas:hover {
        opacity: 0.8;
    }
</style>
</head>
<body>
<div class="container">
    <header>
        <h1>Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance</h1>
        <div class="authors">
            Wenqian Cui¹, Xiaohui Li², Lei Zhu², Zhihan Guo¹, Haoli Bai², Lu Hou², Irwin King¹<br>
            ¹The Chinese University of Hong Kong, ²Huawei Noah's Ark Lab
        </div>
        <div style="margin-top: 20px;">
            <a href="#" style="margin: 0 10px; color: #3498db; text-decoration: none;">[Paper (Coming Soon)]</a>
            <a href="#" style="margin: 0 10px; color: #3498db; text-decoration: none;">[Code (Coming Soon)]</a>
            <a href="#" style="margin: 0 10px; color: #3498db; text-decoration: none;">[Demo]</a>
        </div>
    </header>

    <section class="abstract">
        <h2>Abstract</h2>
        <p>Full-Duplex Speech Language Models (FD-SLMs) are specialized speech foundation models designed to enable natural, real-time spoken interactions by capturing complex conversational dynamics, such as interruptions, backchannels, and overlapping speech. While cascaded FD-SLMs rely on external modules to learn discrete, predefined behaviors for duplex communications, end-to-end (e2e) FD-SLMs leverage real-world conversational data, enabling models to capture nuanced dialogue patterns for more human-like interactions---a key advantage that motivates our focus on e2e systems. However, e2e FD-SLMs face a significant challenge: their conversational abilities often degrade compared to text-based Large Language Models due to the prolonged nature of speech sequences and the scarcity of high-quality spoken dialogue data. To address this, we propose a novel planning-inspired methodology, <b>TurnGuide</b>, for integrating turn-level text guidance into double-channel spoken conversational contexts. Our approach dynamically segments the assistant's speech into dialogue turns and trains the assistant to first output text guidance for each turn before generating the corresponding speech. This not only aligns with conversational flow but also addresses the critical issues of timing and length of text guidance. Extensive experiments demonstrate that our method significantly enhances e2e FD-SLMs' ability to generate semantically meaningful and coherent speech, while preserving the natural flow of full-duplex spoken dialogues.</p>
    </section>

    <section class="demo-section">
        <h2>Audio Demonstrations</h2>
        <div class="note">
            <strong>Note:</strong> The first 30 seconds of audio serves as the prompt to the model, and the model generates a 90 seconds continuations.
        </div>

        <div class="table-container">
            <table class="demo-table">
                <thead>
                    <tr>
                        <th>Original Speech</th>
                        <th colspan="5">Speech Continuations</th>
                    </tr>
                    <tr>
                        <th>Prompt</th>
                        <th>dGSLM</th>
                        <th>SCI</th>
                        <th>Moshi TS</th>
                        <th>TurnGuide (Ours)</th>
                        <th>Ground Truth</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td class="id-column">0</td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-prompt" onclick="seekAudio('0-prompt', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-prompt">Loading...</div>
                                <div class="progress-line" id="progress-0-prompt"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-prompt')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-prompt"></div>
                            <div class="error-message" id="error-0-prompt"></div>
                        </td>
                        <td>
                            <!-- dGSLM cell - rename from ground truth -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-dgslm" onclick="seekAudio('0-dgslm', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-dgslm">Loading...</div>
                                <div class="progress-line" id="progress-0-dgslm"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-dgslm')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-dgslm"></div>
                            <div class="error-message" id="error-0-dgslm"></div>
                        </td>
                        <td>
                            <!-- SCI cell - rename from turnguide -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-sci" onclick="seekAudio('0-sci', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-sci">Loading...</div>
                                <div class="progress-line" id="progress-0-sci"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-sci')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-sci"></div>
                            <div class="error-message" id="error-0-sci"></div>
                        </td>
                        <td>
                            <!-- Moshi TS cell - rename from baseline -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-moshi" onclick="seekAudio('0-moshi', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-moshi">Loading...</div>
                                <div class="progress-line" id="progress-0-moshi"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-moshi')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-moshi"></div>
                            <div class="error-message" id="error-0-moshi"></div>
                        </td>
                        <td>
                            <!-- TurnGuide (Ours) cell - rename from cascaded -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-turnguide" onclick="seekAudio('0-turnguide', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-turnguide">Loading...</div>
                                <div class="progress-line" id="progress-0-turnguide"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-turnguide')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-turnguide"></div>
                            <div class="error-message" id="error-0-turnguide"></div>
                        </td>
                        <td>
                            <!-- Ground Truth cell - new addition -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-0-ground" onclick="seekAudio('0-ground', event)"></canvas>
                                <div class="waveform-loading" id="loading-0-ground">Loading...</div>
                                <div class="progress-line" id="progress-0-ground"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('0-ground')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-0-ground"></div>
                            <div class="error-message" id="error-0-ground"></div>
                        </td>
                    </tr>
                    <tr>
                        <td class="id-column">1</td>
                        <td>
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-prompt" onclick="seekAudio('1-prompt', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-prompt">Loading...</div>
                                <div class="progress-line" id="progress-1-prompt"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-prompt')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-prompt"></div>
                            <div class="error-message" id="error-1-prompt"></div>
                        </td>
                        <td>
                            <!-- dGSLM cell - rename from ground truth -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-dgslm" onclick="seekAudio('1-dgslm', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-dgslm">Loading...</div>
                                <div class="progress-line" id="progress-1-dgslm"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-dgslm')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-dgslm"></div>
                            <div class="error-message" id="error-1-dgslm"></div>
                        </td>
                        <td>
                            <!-- SCI cell - rename from turnguide -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-sci" onclick="seekAudio('1-sci', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-sci">Loading...</div>
                                <div class="progress-line" id="progress-1-sci"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-sci')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-sci"></div>
                            <div class="error-message" id="error-1-sci"></div>
                        </td>
                        <td>
                            <!-- Moshi TS cell - rename from baseline -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-moshi" onclick="seekAudio('1-moshi', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-moshi">Loading...</div>
                                <div class="progress-line" id="progress-1-moshi"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-moshi')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-moshi"></div>
                            <div class="error-message" id="error-1-moshi"></div>
                        </td>
                        <td>
                            <!-- TurnGuide (Ours) cell - rename from cascaded -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-turnguide" onclick="seekAudio('1-turnguide', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-turnguide">Loading...</div>
                                <div class="progress-line" id="progress-1-turnguide"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-turnguide')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-turnguide"></div>
                            <div class="error-message" id="error-1-turnguide"></div>
                        </td>
                        <td>
                            <!-- Ground Truth cell - new addition -->
                            <div class="waveform-container">
                                <canvas class="waveform-canvas" id="waveform-1-ground" onclick="seekAudio('1-ground', event)"></canvas>
                                <div class="waveform-loading" id="loading-1-ground">Loading...</div>
                                <div class="progress-line" id="progress-1-ground"></div>
                            </div>
                            <div class="audio-controls">
                                <button class="play-btn" onclick="playAudio('1-ground')">▶ Play</button>
                            </div>
                            <div class="audio-duration" id="duration-1-ground"></div>
                            <div class="error-message" id="error-1-ground"></div>
                        </td>
                    </tr>
                </tbody>
            </table>
        </div>
    </section>

    <section class="transcript-section">
        <h2>Audio Transcripts</h2>
        <div class="transcript-selector">
            <label for="transcript-select">Select Audio Sample: </label>
            <select id="transcript-select" onchange="showTranscript()">
                <option value="0-prompt">Sample 0 - Prompt</option>
                <option value="0-dgslm">Sample 0 - dGSLM</option>
                <option value="0-sci">Sample 0 - SCI</option>
                <option value="0-moshi">Sample 0 - Moshi TS</option>
                <option value="0-turnguide">Sample 0 - TurnGuide (Ours)</option>
                <option value="0-ground">Sample 0 - Ground Truth</option>
                <option value="1-prompt">Sample 1 - Prompt</option>
                <option value="1-dgslm">Sample 1 - dGSLM</option>
                <option value="1-sci">Sample 1 - SCI</option>
                <option value="1-moshi">Sample 1 - Moshi TS</option>
                <option value="1-turnguide">Sample 1 - TurnGuide (Ours)</option>
                <option value="1-ground">Sample 1 - Ground Truth</option>
            </select>
        </div>
        <div class="transcript-box" id="transcript-display">
            Select an audio sample to view its transcript.
        </div>
    </section>
</div>

<script>
    // Sample transcripts (replace with your actual transcripts)
    const transcripts = {
        '0-prompt': `left speaker, start/end time: (79.18, 81.16), content:  had on a tank top Tonight We went to the club And
left speaker, start/end time: (81.20, 83.56), content:  the little The little midget Looked out there in the
right speaker, start/end time: (81.26, 81.50), content:  Uh-oh.
right speaker, start/end time: (81.64, 90.08), content:  Mm-hmm.
left speaker, start/end time: (83.56, 86.57), content:  water Cause it was like The third row back God damn
left speaker, start/end time: (87.20, 90.96), content:  His arms My brother's got Really huge arms And he started tripping
left speaker, start/end time: (90.96, 94.24), content:  That guy actually Come off the stage Walked his little bitty self Over
right speaker, start/end time: (91.58, 100.94), content:  Right.
left speaker, start/end time: (94.24, 97.20), content:  there to my brother Said this guy's arm Is bigger than my waist He
left speaker, start/end time: (97.20, 100.30), content:  just You know He just had everybody And it was a fun It wasn't a bad
left speaker, start/end time: (100.30, 102.70), content:  thing It was just talking about How big his arm was And that was`,
        '0-dgslm': `This is the dGSLM continuation of the first sample...`,
        '0-sci': `This is the SCI continuation of the first sample...`,
        '0-moshi': `This is the Moshi TS continuation of the first sample...`,
        '0-turnguide': `This is the TurnGuide continuation of the first sample...`,
        '0-ground': `This is the ground truth continuation of the first sample...`,
        '1-prompt': `This is the beginning of the second speech sample...`,
        '1-dgslm': `This is the dGSLM continuation of the second sample...`,
        '1-sci': `This is the SCI continuation of the second sample...`,
        '1-moshi': `This is the Moshi TS continuation of the second sample...`,
        '1-turnguide': `This is the TurnGuide continuation of the second sample...`,
        '1-ground': `This is the ground truth continuation of the second sample...`
    };

    let currentlyPlaying = null;
    let audioElements = {};
    let waveformData = {};
    let audioContext = null;

    function formatTime(seconds) {
        const mins = Math.floor(seconds / 60);
        const secs = Math.floor(seconds % 60);
        return `${mins}:${secs.toString().padStart(2, '0')}`;
    }

    async function loadWaveform(audioId) {
        const canvas = document.getElementById(`waveform-${audioId}`);
        const loadingElement = document.getElementById(`loading-${audioId}`);
        const errorElement = document.getElementById(`error-${audioId}`);
        
        if (!canvas) return;
        
        try {
            // Initialize audio context if not already done
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            // Fetch audio file
            const response = await fetch(`audio/${audioId}.mp3`);
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Extract audio data (use first channel)
            const channelData = audioBuffer.getChannelData(0);
            const samples = channelData.length;
            const canvasWidth = canvas.width = 200;
            const canvasHeight = canvas.height = 80;
            
            // Calculate how many samples per pixel
            const samplesPerPixel = Math.floor(samples / canvasWidth);
            const waveformPoints = [];
            
            // Create waveform data by finding peak values for each pixel
            for (let i = 0; i < canvasWidth; i++) {
                const start = i * samplesPerPixel;
                const end = start + samplesPerPixel;
                let max = 0;
                
                for (let j = start; j < end && j < samples; j++) {
                    const sample = Math.abs(channelData[j]);
                    if (sample > max) {
                        max = sample;
                    }
                }
                
                waveformPoints.push(max);
            }
            
            // Store waveform data for progress animation
            waveformData[audioId] = waveformPoints;
            
            // Draw initial waveform
            drawWaveform(canvas, waveformPoints, 0);

            // Hide loading indicator
            loadingElement.style.display = 'none';

            // Make canvas clickable by adding event listener (backup method)
            canvas.style.cursor = 'pointer';
            
        } catch (error) {
            console.error(`Error loading waveform for ${audioId}:`, error);
            errorElement.textContent = 'Error loading waveform';
            loadingElement.style.display = 'none';
        }
    }

    function drawWaveform(canvas, waveformPoints, progress = 0) {
        const ctx = canvas.getContext('2d');
        const width = canvas.width;
        const height = canvas.height;
        
        // Clear canvas
        ctx.clearRect(0, 0, width, height);
        
        // Draw waveform
        const barWidth = width / waveformPoints.length;
        const progressIndex = Math.floor(progress * waveformPoints.length);
        
        for (let i = 0; i < waveformPoints.length; i++) {
            const barHeight = waveformPoints[i] * height * 0.8; // Scale to 80% of canvas height
            const x = i * barWidth;
            const y = (height - barHeight) / 2;
            
            // Color based on progress
            if (i <= progressIndex) {
                ctx.fillStyle = '#3498db'; // Blue for played portion
            } else {
                ctx.fillStyle = '#e74c3c'; // Red for unplayed portion
            }
            
            ctx.fillRect(x, y, Math.max(barWidth - 1, 1), barHeight);
        }
    }

    function updateWaveformProgress(audioId, progress) {
        const canvas = document.getElementById(`waveform-${audioId}`);
        if (canvas && waveformData[audioId]) {
            drawWaveform(canvas, waveformData[audioId], progress);
        }
    }

    function seekAudio(audioId, event) {
        // Don't seek if audio hasn't been loaded yet
        if (!audioElements[audioId] || !waveformData[audioId]) {
            return;
        }
        
        const canvas = event.target;
        const rect = canvas.getBoundingClientRect();
        const x = event.clientX - rect.left;
        const clickProgress = x / canvas.width;
        
        // Clamp progress between 0 and 1
        const progress = Math.max(0, Math.min(1, clickProgress));
        
        // If audio is loaded, seek to the clicked position
        if (audioElements[audioId].duration) {
            const seekTime = progress * audioElements[audioId].duration;
            audioElements[audioId].currentTime = seekTime;
            
            // Update visual progress immediately
            const progressLine = document.getElementById(`progress-${audioId}`);
            const progressPx = progress * 200;
            progressLine.style.left = progressPx + 'px';
            updateWaveformProgress(audioId, progress);
            
            // If audio wasn't playing, start playing from the clicked position
            if (currentlyPlaying !== audioId) {
                playAudio(audioId);
            }
        }
    }

    function playAudio(audioId) {
        const button = event.target;
        const progressLine = document.getElementById(`progress-${audioId}`);
        const durationElement = document.getElementById(`duration-${audioId}`);
        const errorElement = document.getElementById(`error-${audioId}`);
        
        // Clear any previous error messages
        errorElement.textContent = '';
        
        // Stop any currently playing audio
        if (currentlyPlaying && currentlyPlaying !== audioId) {
            stopAudio(currentlyPlaying);
        }
        
        if (currentlyPlaying === audioId) {
            // Pause current audio
            stopAudio(audioId);
            return;
        }
        
        // Create audio element if it doesn't exist
        if (!audioElements[audioId]) {
            audioElements[audioId] = new Audio(`audio/${audioId}.mp3`);
            
            // Add event listeners
            audioElements[audioId].addEventListener('loadedmetadata', () => {
                const duration = audioElements[audioId].duration;
                durationElement.textContent = `Duration: ${formatTime(duration)}`;
            });
            
            audioElements[audioId].addEventListener('timeupdate', () => {
                const audio = audioElements[audioId];
                const progress = audio.currentTime / audio.duration;
                const progressPx = progress * 200; // 200px is the width
                progressLine.style.left = progressPx + 'px';
                
                // Update waveform progress
                updateWaveformProgress(audioId, progress);
            });
            
            audioElements[audioId].addEventListener('ended', () => {
                stopAudio(audioId);
            });
            
            audioElements[audioId].addEventListener('error', (e) => {
                console.error(`Error loading audio ${audioId}:`, e);
                errorElement.textContent = 'Error loading audio file';
                button.disabled = false;
                button.textContent = '▶ Play';
                button.classList.remove('playing');
            });
            
            audioElements[audioId].addEventListener('canplay', () => {
                button.disabled = false;
            });
        }
        
        // Start playing
        currentlyPlaying = audioId;
        button.textContent = '⏸ Pause';
        button.classList.add('playing');
        button.disabled = true; // Disable during loading
        progressLine.style.opacity = '1';
        
        // Play the audio
        audioElements[audioId].play().then(() => {
            button.disabled = false;
        }).catch((error) => {
            console.error(`Error playing audio ${audioId}:`, error);
            errorElement.textContent = 'Error playing audio file';
            stopAudio(audioId);
        });
    }

    function stopAudio(audioId) {
        const button = document.querySelector(`button[onclick="playAudio('${audioId}')"]`);
        const progressLine = document.getElementById(`progress-${audioId}`);
        
        if (audioElements[audioId]) {
            audioElements[audioId].pause();
            audioElements[audioId].currentTime = 0;
        }
        
        button.textContent = '▶ Play';
        button.classList.remove('playing');
        button.disabled = false;
        progressLine.style.opacity = '0';
        progressLine.style.left = '0px';
        
        // Reset waveform progress
        updateWaveformProgress(audioId, 0);
        
        if (currentlyPlaying === audioId) {
            currentlyPlaying = null;
        }
    }

    function showTranscript() {
        const select = document.getElementById('transcript-select');
        const display = document.getElementById('transcript-display');
        const selectedValue = select.value;
        
        if (transcripts[selectedValue]) {
            display.textContent = transcripts[selectedValue];
        } else {
            display.textContent = 'Transcript not available for this sample.';
        }
    }

    // Initialize waveforms and transcript display
    document.addEventListener('DOMContentLoaded', async () => {
        // Load waveforms for all audio samples
        const audioIds = [
            '0-prompt', '0-dgslm', '0-sci', '0-moshi', '0-turnguide', '0-ground',
            '1-prompt', '1-dgslm', '1-sci', '1-moshi', '1-turnguide', '1-ground'
        ];
        
        // Load waveforms asynchronously
        for (const id of audioIds) {
            loadWaveform(id);
        }
        
        showTranscript();
    });

    // Stop all audio when page is unloaded
    window.addEventListener('beforeunload', () => {
        Object.values(audioElements).forEach(audio => {
            audio.pause();
        });
        if (audioContext) {
            audioContext.close();
        }
    });
</script>
</body>
</html>